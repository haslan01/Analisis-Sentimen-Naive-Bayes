{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2e57b083",
   "metadata": {},
   "source": [
    "# Pelabelan Data Menggunakan Lexicon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4861d5a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import string\n",
    "import numpy as np\n",
    "from Sastrawi.Stemmer.StemmerFactory import StemmerFactory\n",
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7e8b0d1a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Komentar</th>\n",
       "      <th>Label</th>\n",
       "      <th>TOKENIZATION</th>\n",
       "      <th>STOP_REMOVAL</th>\n",
       "      <th>STEMMER</th>\n",
       "      <th>Komentar_Final</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>lha kekerasan seksual itu kan mmg definisinya ...</td>\n",
       "      <td>positif</td>\n",
       "      <td>['lha', 'kekerasan', 'seksual', 'itu', 'kan', ...</td>\n",
       "      <td>['lha', 'kekerasan', 'seksual', 'mmg', 'defini...</td>\n",
       "      <td>['lha', 'keras', 'seksual', 'mmg', 'definisi',...</td>\n",
       "      <td>lha keras seksual mmg definisi tuju korban man...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>jangan mendekati zina itu adalah aturan yang p...</td>\n",
       "      <td>negatif</td>\n",
       "      <td>['jangan', 'mendekati', 'zina', 'itu', 'adalah...</td>\n",
       "      <td>['jangan', 'mendekati', 'zina', 'aturan', 'tid...</td>\n",
       "      <td>['jangan', 'dekat', 'zina', 'atur', 'tidak', '...</td>\n",
       "      <td>jangan dekat zina atur tidak pasal uu dll demo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>the law is an art semakin rinci semakin mudah ...</td>\n",
       "      <td>positif</td>\n",
       "      <td>['the', 'law', 'is', 'an', 'art', 'semakin', '...</td>\n",
       "      <td>['the', 'law', 'is', 'art', 'rinci', 'mudah', ...</td>\n",
       "      <td>['the', 'law', 'is', 'art', 'rinci', 'mudah', ...</td>\n",
       "      <td>the law is art rinci mudah belok</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>tetapkan dulu apa yang dimaksud dengan kekeras...</td>\n",
       "      <td>netral</td>\n",
       "      <td>['tetapkan', 'dulu', 'apa', 'yang', 'dimaksud'...</td>\n",
       "      <td>['tetapkan', 'kekerasan', 'seksualitas']</td>\n",
       "      <td>['tetap', 'keras', 'seksualitas']</td>\n",
       "      <td>tetap keras seksualitas</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>lbih cock diterapkan dikemendikbud dan dpr</td>\n",
       "      <td>netral</td>\n",
       "      <td>['lbih', 'cock', 'diterapkan', 'dikemendikbud'...</td>\n",
       "      <td>['lbih', 'cock', 'diterapkan', 'dikemendikbud'...</td>\n",
       "      <td>['lbih', 'cock', 'terap', 'dikemendikbud', 'dpr']</td>\n",
       "      <td>lbih cock terap dikemendikbud dpr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>641</th>\n",
       "      <td>641</td>\n",
       "      <td>udh lah ganti aja menterinya sekolah pendidika...</td>\n",
       "      <td>negatif</td>\n",
       "      <td>['udh', 'lah', 'ganti', 'aja', 'menterinya', '...</td>\n",
       "      <td>['udh', 'ganti', 'menterinya', 'sekolah', 'pen...</td>\n",
       "      <td>['udh', 'ganti', 'menteri', 'sekolah', 'didik'...</td>\n",
       "      <td>udh ganti menteri sekolah didik amburadul jama...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>642</th>\n",
       "      <td>642</td>\n",
       "      <td>hukum mati slesai lama amat</td>\n",
       "      <td>netral</td>\n",
       "      <td>['hukum', 'mati', 'slesai', 'lama', 'amat']</td>\n",
       "      <td>['hukum', 'mati', 'slesai']</td>\n",
       "      <td>['hukum', 'mati', 'slesai']</td>\n",
       "      <td>hukum mati slesai</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>643</th>\n",
       "      <td>643</td>\n",
       "      <td>laki laki  perempuan  apa</td>\n",
       "      <td>netral</td>\n",
       "      <td>['laki', 'laki', 'perempuan', 'apa']</td>\n",
       "      <td>['laki', 'laki', 'perempuan']</td>\n",
       "      <td>['laki', 'laki', 'perempuan']</td>\n",
       "      <td>laki laki perempuan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>644</th>\n",
       "      <td>644</td>\n",
       "      <td>germo</td>\n",
       "      <td>netral</td>\n",
       "      <td>['germo']</td>\n",
       "      <td>['germo']</td>\n",
       "      <td>['germo']</td>\n",
       "      <td>germo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>645</th>\n",
       "      <td>645</td>\n",
       "      <td>kita gawat daruat dikampus karenahukum tidak j...</td>\n",
       "      <td>negatif</td>\n",
       "      <td>['kita', 'gawat', 'daruat', 'dikampus', 'karen...</td>\n",
       "      <td>['gawat', 'daruat', 'dikampus', 'karenahukum',...</td>\n",
       "      <td>['gawat', 'daruat', 'kampus', 'karenahukum', '...</td>\n",
       "      <td>gawat daruat kampus karenahukum tidak jalan na...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>646 rows Ã— 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Unnamed: 0                                           Komentar    Label  \\\n",
       "0             0  lha kekerasan seksual itu kan mmg definisinya ...  positif   \n",
       "1             1  jangan mendekati zina itu adalah aturan yang p...  negatif   \n",
       "2             2  the law is an art semakin rinci semakin mudah ...  positif   \n",
       "3             3  tetapkan dulu apa yang dimaksud dengan kekeras...   netral   \n",
       "4             4        lbih cock diterapkan dikemendikbud dan dpr    netral   \n",
       "..          ...                                                ...      ...   \n",
       "641         641  udh lah ganti aja menterinya sekolah pendidika...  negatif   \n",
       "642         642                        hukum mati slesai lama amat   netral   \n",
       "643         643                         laki laki  perempuan  apa    netral   \n",
       "644         644                                              germo   netral   \n",
       "645         645  kita gawat daruat dikampus karenahukum tidak j...  negatif   \n",
       "\n",
       "                                          TOKENIZATION  \\\n",
       "0    ['lha', 'kekerasan', 'seksual', 'itu', 'kan', ...   \n",
       "1    ['jangan', 'mendekati', 'zina', 'itu', 'adalah...   \n",
       "2    ['the', 'law', 'is', 'an', 'art', 'semakin', '...   \n",
       "3    ['tetapkan', 'dulu', 'apa', 'yang', 'dimaksud'...   \n",
       "4    ['lbih', 'cock', 'diterapkan', 'dikemendikbud'...   \n",
       "..                                                 ...   \n",
       "641  ['udh', 'lah', 'ganti', 'aja', 'menterinya', '...   \n",
       "642        ['hukum', 'mati', 'slesai', 'lama', 'amat']   \n",
       "643               ['laki', 'laki', 'perempuan', 'apa']   \n",
       "644                                          ['germo']   \n",
       "645  ['kita', 'gawat', 'daruat', 'dikampus', 'karen...   \n",
       "\n",
       "                                          STOP_REMOVAL  \\\n",
       "0    ['lha', 'kekerasan', 'seksual', 'mmg', 'defini...   \n",
       "1    ['jangan', 'mendekati', 'zina', 'aturan', 'tid...   \n",
       "2    ['the', 'law', 'is', 'art', 'rinci', 'mudah', ...   \n",
       "3             ['tetapkan', 'kekerasan', 'seksualitas']   \n",
       "4    ['lbih', 'cock', 'diterapkan', 'dikemendikbud'...   \n",
       "..                                                 ...   \n",
       "641  ['udh', 'ganti', 'menterinya', 'sekolah', 'pen...   \n",
       "642                        ['hukum', 'mati', 'slesai']   \n",
       "643                      ['laki', 'laki', 'perempuan']   \n",
       "644                                          ['germo']   \n",
       "645  ['gawat', 'daruat', 'dikampus', 'karenahukum',...   \n",
       "\n",
       "                                               STEMMER  \\\n",
       "0    ['lha', 'keras', 'seksual', 'mmg', 'definisi',...   \n",
       "1    ['jangan', 'dekat', 'zina', 'atur', 'tidak', '...   \n",
       "2    ['the', 'law', 'is', 'art', 'rinci', 'mudah', ...   \n",
       "3                    ['tetap', 'keras', 'seksualitas']   \n",
       "4    ['lbih', 'cock', 'terap', 'dikemendikbud', 'dpr']   \n",
       "..                                                 ...   \n",
       "641  ['udh', 'ganti', 'menteri', 'sekolah', 'didik'...   \n",
       "642                        ['hukum', 'mati', 'slesai']   \n",
       "643                      ['laki', 'laki', 'perempuan']   \n",
       "644                                          ['germo']   \n",
       "645  ['gawat', 'daruat', 'kampus', 'karenahukum', '...   \n",
       "\n",
       "                                        Komentar_Final  \n",
       "0    lha keras seksual mmg definisi tuju korban man...  \n",
       "1    jangan dekat zina atur tidak pasal uu dll demo...  \n",
       "2                     the law is art rinci mudah belok  \n",
       "3                              tetap keras seksualitas  \n",
       "4                    lbih cock terap dikemendikbud dpr  \n",
       "..                                                 ...  \n",
       "641  udh ganti menteri sekolah didik amburadul jama...  \n",
       "642                                  hukum mati slesai  \n",
       "643                                laki laki perempuan  \n",
       "644                                              germo  \n",
       "645  gawat daruat kampus karenahukum tidak jalan na...  \n",
       "\n",
       "[646 rows x 7 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"preprocessing.csv\")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "615a2235",
   "metadata": {},
   "outputs": [],
   "source": [
    "word_dict = {}\n",
    "for i in range(0,len(df['Komentar'])):\n",
    "    sentence = df['Komentar'][i]\n",
    "    word_token = word_tokenize(sentence)\n",
    "    for j in word_token:\n",
    "        if j not in word_dict:\n",
    "            word_dict[j] = 1\n",
    "        else:\n",
    "            word_dict[j] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "73b5ecab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1934"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(word_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "85aaa88c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1156"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len({k:v for (k,v) in word_dict.items() if v < 4})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6b95f7c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "negasi = ['bukan','tidak','ga','gk']\n",
    "lexicon = pd.read_csv('lexicon/modified_full_lexicon.csv')\n",
    "lexicon = lexicon.drop(lexicon[(lexicon['word'] == 'bukan')\n",
    "                               |(lexicon['word'] == 'tidak')\n",
    "                               |(lexicon['word'] == 'ga')\n",
    "                               |(lexicon['word'] == 'gk') ].index,axis=0)\n",
    "lexicon = lexicon.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "17e366bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10248"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(lexicon)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f8ef3af3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>weight</th>\n",
       "      <th>number_of_words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>hai</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>merekam</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ekstensif</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>paripurna</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>detail</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>pernik</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>belas</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>welas</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>kabung</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>rahayu</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        word  weight  number_of_words\n",
       "0        hai       3                1\n",
       "1    merekam       2                1\n",
       "2  ekstensif       3                1\n",
       "3  paripurna       1                1\n",
       "4     detail       2                1\n",
       "5     pernik       3                1\n",
       "6      belas       2                1\n",
       "7      welas       4                1\n",
       "8     kabung       1                1\n",
       "9     rahayu       4                1"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lexicon.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f58a9b4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "lexicon_word = lexicon['word'].to_list()\n",
    "lexicon_num_words = lexicon['number_of_words']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "15f45694",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10248"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(lexicon_word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "965239ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "ns_words = []\n",
    "factory = StemmerFactory()\n",
    "stemmer = factory.create_stemmer()\n",
    "for word in word_dict.keys():\n",
    "    if word not in lexicon_word:\n",
    "        kata_dasar = stemmer.stem(word)\n",
    "        if kata_dasar not in lexicon_word:\n",
    "            ns_words.append(word)\n",
    "len(ns_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6d56224",
   "metadata": {},
   "outputs": [],
   "source": [
    "len({k:v for (k,v) in word_dict.items() if ((k in ns_words)&(v>3)) })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4697e4cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "ns_words_list = {k:v for (k,v) in word_dict.items() if ((k in ns_words)&(v>3))}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6ec01f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "sort_orders = sorted(ns_words_list.items(), key=lambda x: x[1], reverse=True)\n",
    "sort_orders=sort_orders[0:20]\n",
    "for i in sort_orders:\n",
    "    print(i[0], i[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07f13c61",
   "metadata": {},
   "outputs": [],
   "source": [
    "lexicon['number_of_words'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfb604c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "sencol =[]\n",
    "senrow =np.array([])\n",
    "nsen = 0\n",
    "factory = StemmerFactory()\n",
    "stemmer = factory.create_stemmer()\n",
    "sentiment_list = []\n",
    "# function to write the word's sentiment if it is founded\n",
    "def found_word(ind,words,word,sen,sencol,sentiment,add):\n",
    "    # if it is already included in the bag of words matrix, then just increase the value\n",
    "    if word in sencol:\n",
    "        sen[sencol.index(word)] += 1\n",
    "    else:\n",
    "    #if not, than add new word\n",
    "        sencol.append(word)\n",
    "        sen.append(1)\n",
    "        add += 1\n",
    "    #if there is a negation word before it, the sentiment would be the negation of it's sentiment\n",
    "    if (words[ind-1] in negasi):\n",
    "        sentiment += -lexicon['weight'][lexicon_word.index(word)]\n",
    "    else:\n",
    "        sentiment += lexicon['weight'][lexicon_word.index(word)]\n",
    "    \n",
    "    return sen,sencol,sentiment,add\n",
    "            \n",
    "# checking every words, if they are appear in the lexicon, and then calculate their sentiment if they do\n",
    "for i in range(len(df)):\n",
    "    nsen = senrow.shape[0]\n",
    "    words = word_tokenize(df['Komentar'][i])\n",
    "    sentiment = 0 \n",
    "    add = 0\n",
    "    prev = [0 for ii in range(len(words))]\n",
    "    n_words = len(words)\n",
    "    if len(sencol)>0:\n",
    "        sen =[0 for j in range(len(sencol))]\n",
    "    else:\n",
    "        sen =[]\n",
    "    \n",
    "    for word in words:\n",
    "        ind = words.index(word)\n",
    "        # check whether they are included in the lexicon\n",
    "        if word in lexicon_word :\n",
    "            sen,sencol,sentiment,add= found_word(ind,words,word,sen,sencol,sentiment,add)\n",
    "        else:\n",
    "        # if not, then check the root word\n",
    "            kata_dasar = stemmer.stem(word)\n",
    "            if kata_dasar in lexicon_word:\n",
    "                sen,sencol,sentiment,add= found_word(ind,words,kata_dasar,sen,sencol,sentiment,add)\n",
    "        # if still negative, try to match the combination of words with the adjacent words\n",
    "            elif(n_words>1):\n",
    "                if ind-1>-1:\n",
    "                    back_1    = words[ind-1]+' '+word\n",
    "                    if (back_1 in lexicon_word):\n",
    "                        sen,sencol,sentiment,add= found_word(ind,words,back_1,sen,sencol,sentiment,add)\n",
    "                    elif(ind-2>-1):\n",
    "                        back_2    = words[ind-2]+' '+back_1\n",
    "                        if back_2 in lexicon_word:\n",
    "                            sen,sencol,sentiment,add= found_word(ind,words,back_2,sen,sencol,sentiment,add)\n",
    "    # if there is new word founded, then expand the matrix\n",
    "    if add>0:  \n",
    "        if i>0:\n",
    "            if (nsen==0):\n",
    "                senrow = np.zeros([i,add],dtype=int)\n",
    "            elif(i!=nsen):\n",
    "                padding_h = np.zeros([nsen,add],dtype=int)\n",
    "                senrow = np.hstack((senrow,padding_h))\n",
    "                padding_v = np.zeros([(i-nsen),senrow.shape[1]],dtype=int)\n",
    "                senrow = np.vstack((senrow,padding_v))\n",
    "            else:\n",
    "                padding =np.zeros([nsen,add],dtype=int)\n",
    "                senrow = np.hstack((senrow,padding))\n",
    "            senrow = np.vstack((senrow,sen))\n",
    "        if i==0:\n",
    "            senrow = np.array(sen).reshape(1,len(sen))\n",
    "    # if there isn't then just update the old matrix\n",
    "    elif(nsen>0):\n",
    "        senrow = np.vstack((senrow,sen))\n",
    "        \n",
    "    sentiment_list.append(sentiment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4405e6f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(sentiment_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7188fe3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(senrow.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e12d69de",
   "metadata": {},
   "outputs": [],
   "source": [
    "sencol.append('sentiment')\n",
    "sentiment_array = np.array(sentiment_list).reshape(senrow.shape[0],1)\n",
    "sentiment_data = np.hstack((senrow,sentiment_array))\n",
    "df_sen = pd.DataFrame(sentiment_data,columns = sencol)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e86837ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sen.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5865c45f",
   "metadata": {},
   "outputs": [],
   "source": [
    "cek_df = pd.DataFrame([])\n",
    "cek_df['text'] = df['Komentar'].copy()\n",
    "cek_df['sentiment']  = df_sen['sentiment'].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fe5bf84",
   "metadata": {},
   "outputs": [],
   "source": [
    "cek_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f3b65fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "cek_df['sentiment'] = df_sen['sentiment'].copy()\n",
    "df.loc[cek_df['sentiment']>=0, 'sentiment'] = 1 #positive\n",
    "df.loc[cek_df['sentiment']<0, 'sentiment'] = 0 #negative\n",
    "df.loc[cek_df['sentiment']==0, 'sentiment'] = 2 #netral\n",
    "# df.drop(df[cek_df.sentiment==0].index, inplace=True)\n",
    "# df.reset_index()\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "103ef3ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(\"Label\",axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83d500d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9735b5f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('lexiconDataLabelling.csv')\n",
    "# df.to_excel('data fix\\datalabeled.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a200cdee",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
